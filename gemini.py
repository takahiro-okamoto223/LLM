# -*- coding: utf-8 -*-
"""LLM_SPAM_gemini.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19TGtREX528jqLPk-xBWRt8e64GN6L5PI
"""

import google.generativeai as genai
import os
import time
from google.colab import drive
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# Google Gemini APIキーの設定
genai.configure(api_key='AIzaSyAh_v5LS5m4t1vExEx2TANdl5E1CMiugMc')

# Google Driveのマウント
drive.mount('/content/drive', force_remount=True)

# メールフォルダのパス
folder_path = "/content/drive/MyDrive/train2"

# バッチサイズの設定（1バッチに含めるメールの数）
BATCH_SIZE = 5

# geminiモデルを作成
model = genai.GenerativeModel('gemini-1.5-flash')

# バッチ処理を行う関数
def batch_is_spam(emails):
    results = []
    # 複数のミニバッチに分けて処理
    for i in range(0, len(emails), BATCH_SIZE):
        mini_batch = emails[i:i + BATCH_SIZE]

        prompts = "\n".join([f"{j+1}. Content: {email}" for j, email in enumerate(mini_batch)])
        prompt = (
              f"You are a security expert specializing in email security and spam detection."
              f"You must analyze the following email contents and classify them as either 'spam' or 'not spam'."
              f"Spam emails typically contain phishing attempts, fraudulent offers, or excessive advertisements."
              f"For each email content, respond with 'TRUE' if it is spam and 'FALSE' otherwise."
              f"The output format must be exactly 'TRUE' or 'FALSE' with no additional text. \n\n{prompts}"
        ) #0でスパム判定

        # Gemini APIでリクエストを送信
        response = model.generate_content(
            prompt,
            safety_settings={
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            },
            generation_config=genai.types.GenerationConfig(
                max_output_tokens=10 * BATCH_SIZE)
        )

        """response = model.generate_content(prompt)"""
        # textにアクセスする前に、レスポンスにコンテンツが含まれているかどうかをチェックする
        if response.candidates:
            try:
                print(response.text)
                batch_results = response.text.splitlines()  # 各行をリストに分割

                # ミニバッチのサイズと一致するように調整
                if len(batch_results) < len(mini_batch):
                    print(f"Warning: Expected {len(mini_batch)} results, but got {len(batch_results)}. Filling missing entries with 'S'.")
                    batch_results += ["S"] * (len(mini_batch) - len(batch_results))
                results.extend([line.strip() if line.strip() in {"TRUE", "FALSE"} else "X" for line in batch_results])
                print(results)
            except ValueError:
                results.extend(["S"] * len(mini_batch))
                print("Invalid response format. Skipping this batch.")
        else:
            results.extend(["S"] * len(mini_batch))
            print(f"Prompt blocked: {response.prompt_feedback}")
            # ブロックされたプロンプトの処理

        #1バッチ当たりに消費したトークン数
        print(f"Token count for this batch: {response.usage_metadata}")

        # Rate limiting対策: 各リクエスト後に一時停止
        time.sleep(5)

    return results

# フォルダ内のすべてのtxtファイルを読み込む
emails = []
sorted_filenames = sorted([filename for filename in os.listdir(folder_path) if filename.endswith(".txt")])

for filename in sorted_filenames:
    with open(os.path.join(folder_path, filename), "r", encoding="utf-8") as file:
        emails.append(file.read())  # メール本文をリストに追加

# バッチでスパム判定を実行
results = batch_is_spam(emails)

# 出力結果を保存するファイルを開く TRUEがスパム
with open("0500-prompt.txt", "w") as output_file:
    # ヘッダーをファイルに出力
    output_file.write("file_name\tlabel\n")

    # ファイル名、メール内容、スパム判定結果をループで処理
    for filename, is_spam in zip(sorted_filenames, results):
        if is_spam == "S" or is_spam == "X":
            label = "skip"  # Skippedの場合
        elif is_spam == "TRUE":
            label = "1"
        else:
            label = "0"     # 1がスパム、0が非スパム

        # 指定の形式でファイルに出力
        output_file.write(f"{filename}\t{label}\n")
